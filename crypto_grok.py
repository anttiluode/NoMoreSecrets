"""
CRYPTO GROK: THE LATTICE BREAKER
================================
Can RCNet find the secret key hidden inside visual noise?

1. THE SECRET: A Lattice Pattern generated by (Ax + By) % 255.
   To the eye, this looks like pure white noise (TV static).
   
2. THE AI: RCNet takes (x, y) coordinates and predicts grayscale value.

3. THE TEST: If RCNet learns the 'Phase Frequency', it has cracked the key.
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ============================================================================
# 1. THE ENIGMA MACHINE (Visual Lattice Generator)
# ============================================================================
def generate_lattice_noise(size=128, key_a=53, key_b=19):
    """
    Generates a grid where Value = (A*x + B*y) % 255.
    With prime keys, this creates a pseudo-random lattice (Noise).
    """
    x = np.arange(size)
    y = np.arange(size)
    X, Y = np.meshgrid(x, y)
    
    # The Trapdoor Function (Modulo Arithmetic)
    # Normalize to 0-1 for the neural net
    noise = (key_a * X + key_b * Y) % 255
    noise = noise.astype(np.float32) / 255.0
    
    return torch.tensor(noise).unsqueeze(0) # [1, H, W]

# ============================================================================
# 2. THE RESONANT CORTEX (Standard)
# ============================================================================
class ComplexLinear(nn.Module):
    def __init__(self, in_features, out_features):
        super().__init__()
        self.fc_r = nn.Linear(in_features, out_features, bias=False)
        self.fc_i = nn.Linear(in_features, out_features, bias=False)
        nn.init.xavier_normal_(self.fc_r.weight, gain=0.1)
        nn.init.xavier_normal_(self.fc_i.weight, gain=0.1)

    def forward(self, z):
        real_out = self.fc_r(z.real) - self.fc_i(z.imag)
        imag_out = self.fc_r(z.imag) + self.fc_i(z.real)
        return torch.complex(real_out, imag_out)

class ResonantColumn(nn.Module):
    def __init__(self, width):
        super().__init__()
        self.mixer = ComplexLinear(width, width)
        self.bias_phase = nn.Parameter(torch.randn(width) * 0.1)

    def forward(self, z):
        z_mixed = self.mixer(z)
        amp = torch.tanh(torch.abs(z_mixed)) 
        phase = torch.angle(z_mixed) + self.bias_phase 
        return torch.polar(amp, phase)

class RCNet_Breaker(nn.Module):
    def __init__(self, hidden_dim=64):
        super().__init__()
        # Input: (x, y) normalized coordinates
        self.input_r = nn.Linear(2, hidden_dim)
        self.input_i = nn.Linear(2, hidden_dim)
        
        self.column = ResonantColumn(hidden_dim)
        
        # Readout: Complex -> Real Value (0-1)
        self.readout = nn.Linear(hidden_dim * 2, 1)

    def forward(self, x):
        r = self.input_r(x); i = self.input_i(x)
        z = torch.complex(r, i)
        
        z = z + self.column(z)
        
        cat = torch.cat([z.real, z.imag], dim=1)
        return torch.sigmoid(self.readout(cat))

# ============================================================================
# 3. EXPERIMENT
# ============================================================================
def crack_cipher(device):
    SIZE = 64
    KEY_A = 67 # Secret Prime A
    KEY_B = 31 # Secret Prime B
    
    print(f"üîê Encrypting Image with Keys A={KEY_A}, B={KEY_B}...")
    target_image = generate_lattice_noise(SIZE, KEY_A, KEY_B).to(device)
    
    # Prepare coordinate grid (Inputs)
    y, x = torch.meshgrid(torch.linspace(0, 1, SIZE), torch.linspace(0, 1, SIZE), indexing='ij')
    coords = torch.stack([x, y], dim=-1).reshape(-1, 2).to(device) # [N, 2]
    targets = target_image.reshape(-1, 1)
    
    model = RCNet_Breaker().to(device)
    opt = optim.AdamW(model.parameters(), lr=0.01)
    crit = nn.MSELoss()
    
    print("üß† Attempting to Grok the Pattern...")
    history = []
    
    for epoch in range(110000):
        model.train()
        opt.zero_grad()
        
        pred = model(coords)
        loss = crit(pred, targets)
        
        loss.backward()
        opt.step()
        history.append(loss.item())
        
        if epoch % 100 == 0:
            print(f"Ep {epoch} | MSE: {loss.item():.5f}")

    # =================================================================       
    # 4. VISUALIZATION
    # =================================================================
    print("\nVisualizing Decryption...")
    model.eval()
    with torch.no_grad():
        reconstruction = model(coords).reshape(SIZE, SIZE).cpu().numpy()
        truth = target_image.cpu().squeeze().numpy()
        
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # 1. The "Noise" (What standard AI sees)
    axes[0].imshow(truth, cmap='gray')
    axes[0].set_title("The Encrypted Signal\n(Looks like Noise)")
    axes[0].axis('off')
    
    # 2. The AI's View
    axes[1].imshow(reconstruction, cmap='gray')
    axes[1].set_title(f"RCNet Reconstruction\nMSE: {loss.item():.5f}")
    axes[1].axis('off')
    
    # 3. The Error Map (Did we crack it?)
    diff = np.abs(truth - reconstruction)
    axes[2].imshow(diff, cmap='inferno')
    axes[2].set_title("Residual Error\n(Black = Cracked)")
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.savefig('crypto_grok.png')
    print("Saved 'crypto_grok.png'")
    
    # Analyze the weights to see if Key A/B are there?
    # In a real CVNN, the input weights often converge to 2*pi*Key
    print("\nAnalysis:")
    print("If the middle image looks exactly like the left image,")
    print("RCNet has successfully unwrapped the modulo space.")
    print("It found the linear function hidden inside the static.")

if __name__ == '__main__':
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    crack_cipher(device)